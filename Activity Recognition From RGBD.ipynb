{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actity Recognition From RGB-D Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "import lightnet as ln\n",
    "from fastai.vision import *\n",
    "import xml.etree.cElementTree as ET\n",
    "import matplotlib\n",
    "from fastai.metrics import error_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"/home/jupyter/storage/UTKinect_Dataset\"\n",
    "folders = [\"depth\",\"rgb\"]\n",
    "label_fname = \"actionLabel.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_url = \"https://cvrc.ece.utexas.edu/KinectDatasets/depth.zip\"\n",
    "rgb_url = \"https://cvrc.ece.utexas.edu/KinectDatasets/RGB.zip\"\n",
    "label_url = \"https://cvrc.ece.utexas.edu/KinectDatasets/actionLabel.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_url(depth_url,dataset_path+\"/depth.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_url(rgb_url,dataset_path+\"/rgb.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_url(label_url,\"%s/%s\"%(dataset_path,label_fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\"depth\":[],\"rgb\":[],\"labels\":[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_Arr_to_float(str_arr):\n",
    "    \"\"\"\n",
    "    func: convert all string numbers in list to float\n",
    "    param:  list of string numbers\n",
    "    out:  list of float numbers\n",
    "    \"\"\"\n",
    "    for x in range(len(str_arr)):\n",
    "        str_arr[x] = float(str_arr[x])\n",
    "    return str_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def depth_xml_to_arr(imgFilePath, depthFilePath,beginFrm, endFrm, label):\n",
    "    \"\"\"\n",
    "    func: load depth image data from given range of frames, and append label\n",
    "    param: depthFilePath - path to file where frames are found\n",
    "           beginFrm - first frame of activty \n",
    "           endFrm - last frame of activty\n",
    "           label - label of activity\n",
    "    out: list of touples contatining depth data of each frame between beginFrm and endFrm and label\n",
    "    \"\"\"  \n",
    "    xmlFiles = [f for f in os.listdir(depthFilePath) if f.endswith('.xml')]\n",
    "    xmlFiles.sort(key=lambda item: (len(item), item))\n",
    "    \n",
    "    depthSequence = [[],[]]\n",
    "    \n",
    "    beginFrmFile = \"depthImg%i.xml\" %beginFrm\n",
    "    endFrmFile = \"depthImg%i.xml\" %endFrm\n",
    "    \n",
    "    beginIdx = xmlFiles.index(beginFrmFile)\n",
    "    endIdx = xmlFiles.index(endFrmFile)\n",
    "    useXmlFiles = xmlFiles[beginIdx:endIdx+1]\n",
    "    \n",
    "    for xmlFile in useXmlFiles:\n",
    "        imgFile = xmlFile.replace(\"depthImg\",\"colorImg\").replace(\".xml\",\".jpg\")\n",
    "        img = PIL.Image.open(os.path.join(imgFilePath, imgFile))\n",
    "        \n",
    "        tree = ET.parse(os.path.join(depthFilePath, xmlFile))\n",
    "        filename, _ = os.path.splitext(xmlFile)\n",
    "        elem = tree.find('%s/data' % filename)\n",
    "        strData = elem.text\n",
    "        str_Arr = strData.split()\n",
    "        floatData = string_Arr_to_float(str_Arr)\n",
    "        arr = np.array(floatData)\n",
    "        depthData = np.array(floatData).reshape(240, 320)\n",
    "        \n",
    "        img = img.resize((320,240))\n",
    "        \n",
    "        data_dict[\"rgb\"].append(img)\n",
    "        data_dict[\"depth\"].append(depthData)\n",
    "        data_dict[\"labels\"].append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should do similar to depth_xml_to_arr, but with rgb images instead of depth\n",
    "def img_to_arr(imgFilePath,beginFrm, endFrm, label):\n",
    "    imgs = []\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_depth_imgs(img_path,depth_path,label_fname):\n",
    "    \"\"\"\n",
    "    func: load depth image data from xml file\n",
    "    param: depth_path - path to folder with depth data\n",
    "           label_fname - name of the label txt file\n",
    "    out: list of touples with depth img and activity label\n",
    "    \"\"\"    \n",
    "    configFile = os.path.join(dataset_path, label_fname)\n",
    "    with open(configFile, \"r\") as f:\n",
    "        lines = f.read().splitlines()\n",
    "\n",
    "    for i in range(0,220,11):\n",
    "        currLines = lines[i:i+11]\n",
    "        depthFileDir = currLines[0]\n",
    "\n",
    "        print(\"loading %s\" %depthFileDir)\n",
    "        for line in currLines[1:]:\n",
    "                splitIdx = line.index(\":\")\n",
    "                label = line[:splitIdx]\n",
    "                nums = line[splitIdx+1:].split()\n",
    "                beginFrm = int(nums[0])\n",
    "                endFrm = int(nums[1])\n",
    "                \n",
    "                depthFilePath = os.path.join(depth_path,depthFileDir)\n",
    "                imgFilePath = os.path.join(img_path,depthFileDir)\n",
    "                \n",
    "                depth_xml_to_arr(imgFilePath, depthFilePath,beginFrm, endFrm, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading s01_e01\n",
      "loading s01_e02\n",
      "loading s02_e01\n",
      "loading s02_e02\n",
      "loading s03_e01\n",
      "loading s03_e02\n",
      "loading s04_e01\n",
      "loading s04_e02\n",
      "loading s05_e01\n",
      "loading s05_e02\n",
      "loading s06_e01\n",
      "loading s06_e02\n",
      "loading s07_e01\n",
      "loading s07_e02\n",
      "loading s08_e01\n",
      "loading s08_e02\n",
      "loading s09_e01\n"
     ]
    }
   ],
   "source": [
    "depth_path = dataset_path + \"/depth\"\n",
    "img_path = dataset_path + \"/RGB\"\n",
    "load_depth_imgs(img_path,depth_path,label_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_dict[\"rgb\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected np.ndarray (got tuple)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-9f429a91016e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: expected np.ndarray (got tuple)"
     ]
    }
   ],
   "source": [
    "train_set, val_set = torch.utils.data.random_split(dataset, [50000, 10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(inps, tgts)\n",
    "loader = DataLoader(dataset, batch_size=2, collate_fn=collate_wrapper,\n",
    "                    pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YoloFusion(\n",
       "  (layers): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (fuse): Conv2d(4, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1_convbatch): Conv2dBatchReLU(3, 32, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1))\n",
       "    )\n",
       "    (1): Fusion(\n",
       "      (Combined): Sequential(\n",
       "        (2_max): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (3_convbatch): Conv2dBatchReLU(32, 64, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1))\n",
       "        (4_max): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (5_convbatch): Conv2dBatchReLU(64, 128, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1))\n",
       "        (6_convbatch): Conv2dBatchReLU(128, 64, kernel_size=1, stride=1, padding=0, LeakyReLU(negative_slope=0.1))\n",
       "        (7_convbatch): Conv2dBatchReLU(64, 128, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1))\n",
       "        (8_max): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (9_convbatch): Conv2dBatchReLU(128, 256, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1))\n",
       "        (10_convbatch): Conv2dBatchReLU(256, 128, kernel_size=1, stride=1, padding=0, LeakyReLU(negative_slope=0.1))\n",
       "        (11_convbatch): Conv2dBatchReLU(128, 256, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1))\n",
       "        (12_max): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (13_convbatch): Conv2dBatchReLU(256, 512, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1))\n",
       "        (14_convbatch): Conv2dBatchReLU(512, 256, kernel_size=1, stride=1, padding=0, LeakyReLU(negative_slope=0.1))\n",
       "        (15_convbatch): Conv2dBatchReLU(256, 512, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1))\n",
       "        (16_convbatch): Conv2dBatchReLU(512, 256, kernel_size=1, stride=1, padding=0, LeakyReLU(negative_slope=0.1))\n",
       "        (17_convbatch): Conv2dBatchReLU(256, 512, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1))\n",
       "      )\n",
       "    (2): Fusion(\n",
       "      (Combined): Sequential(\n",
       "        (18_max): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (19_convbatch): Conv2dBatchReLU(512, 1024, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1))\n",
       "        (20_convbatch): Conv2dBatchReLU(1024, 512, kernel_size=1, stride=1, padding=0, LeakyReLU(negative_slope=0.1))\n",
       "        (21_convbatch): Conv2dBatchReLU(512, 1024, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1))\n",
       "        (22_convbatch): Conv2dBatchReLU(1024, 512, kernel_size=1, stride=1, padding=0, LeakyReLU(negative_slope=0.1))\n",
       "        (23_convbatch): Conv2dBatchReLU(512, 1024, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1))\n",
       "        (24_convbatch): Conv2dBatchReLU(1024, 1024, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1))\n",
       "        (25_convbatch): Conv2dBatchReLU(1024, 1024, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1))\n",
       "      )\n",
       "    (3): Fusion(\n",
       "      (Combined): Sequential(\n",
       "        (26_convbatch): Conv2dBatchReLU(1280, 1024, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1))\n",
       "        (27_conv): Conv2d(1024, 125, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    (4): Sequential(\n",
       "      (P1_convbatch): Conv2dBatchReLU(512, 64, kernel_size=1, stride=1, padding=0, LeakyReLU(negative_slope=0.1))\n",
       "      (P2_reorg): Reorg(stride=2)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ln.models.YoloFusion(); model"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cu101.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu101:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
