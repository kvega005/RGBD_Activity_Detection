{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actity Recognition From RGB-D Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import lightnet as ln\n",
    "import os\n",
    "import xml.etree.cElementTree as ET\n",
    "from fastai.vision import *\n",
    "from fastai.metrics import error_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"/storage/UTKinect_Dataset\"\n",
    "folders = [\"depth\",\"rgb\"]\n",
    "label_fname = \"actionLabel.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_Arr_to_float(str_arr):\n",
    "    \"\"\"\n",
    "    func: convert all string numbers in list to float\n",
    "    param:  list of string numbers\n",
    "    out:  list of float numbers\n",
    "    \"\"\"\n",
    "    for x in range(len(str_arr)):\n",
    "        try:\n",
    "            str_arr[x] = float(str_arr[x])\n",
    "    return str_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def depth_xml_to_arr(depthFilePath,beginFrm, endFrm, label):\n",
    "    \"\"\"\n",
    "    func: load depth image data from given range of frames, and append label\n",
    "    param: depthFilePath - path to file where frames are found\n",
    "           beginFrm - first frame of activty \n",
    "           endFrm - last frame of activty\n",
    "           label - label of activity\n",
    "    out: list of touples contatining depth data of each frame between beginFrm and endFrm and label\n",
    "    \"\"\"\n",
    "    xmlFiles = [f for f in os.listdir(depthFilePath) if f.endswith('.xml')]\n",
    "    xmlFiles.sort(key=lambda item: (len(item), item))\n",
    "    depthSequence = []\n",
    "    \n",
    "    beginFrmFile = \"depthImg%i.xml\" %beginFrm\n",
    "    endFrmFile = \"depthImg%i.xml\" %endFrm\n",
    "    \n",
    "    beginIdx = xmlFiles.index(beginFrmFile)\n",
    "    endIdx = xmlFiles.index(endFrmFile)\n",
    "    useXmlFiles = xmlFiles[beginIdx:endIdx+1]\n",
    "    \n",
    "    for xmlFile in useXmlFiles:\n",
    "        try:\n",
    "            tree = ET.parse(os.path.join(depthFilePath, xmlFile))\n",
    "            filename, _ = os.path.splitext(xmlFile)\n",
    "            elem = tree.find('%s/data' % filename)\n",
    "            strData = elem.text\n",
    "            str_Arr = strData.split()\n",
    "            floatData = string_Arr_to_float(str_Arr)\n",
    "            arr = np.array(floatData)\n",
    "            depthData = np.array(floatData).reshape(240, 320)\n",
    "            depthSequence.append((depthData,label))\n",
    "        except:\n",
    "            print(\"Problem in: %s\" %xmlFile)\n",
    "    return depthSequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_depth_imgs(depth_path,label_fname):\n",
    "    \"\"\"\n",
    "    func: load depth image data from xml file\n",
    "    param: depth_path - path to folder with depth data\n",
    "           label_fname - name of the label txt file\n",
    "    out: list of touples with depth img and activity label\n",
    "    \"\"\"\n",
    "    depth_data = []\n",
    "    \n",
    "    configFile = os.path.join(dataset_path, label_fname)\n",
    "    with open(configFile, \"r\") as f:\n",
    "        lines = f.read().splitlines()\n",
    "\n",
    "    for i in range(0,220,11):\n",
    "        currLines = lines[i:i+11]\n",
    "        depthFileDir = currLines[0]\n",
    "\n",
    "        print(\"loading %s\" %depthFileDir)\n",
    "        for line in currLines[1:]:\n",
    "                splitIdx = line.index(\":\")\n",
    "                label = line[:splitIdx]\n",
    "                nums = line[splitIdx+1:].split()\n",
    "                beginFrm = int(nums[0])\n",
    "                endFrm = int(nums[1])\n",
    "                depthFilePath = os.path.join(depth_path,depthFileDir)\n",
    "                depth_data.extend(depth_xml_to_arr(depthFilePath,beginFrm, endFrm, label))\n",
    "        \n",
    "    return depth_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Will update soon\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YoloFusion(\n",
       "  (layers): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (fuse): Conv2d(4, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1_convbatch): Conv2dBatchReLU(3, 32, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1))\n",
       "    )\n",
       "    (1): Fusion(\n",
       "      (Combined): Sequential(\n",
       "        (2_max): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (3_convbatch): Conv2dBatchReLU(32, 64, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1))\n",
       "        (4_max): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (5_convbatch): Conv2dBatchReLU(64, 128, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1))\n",
       "        (6_convbatch): Conv2dBatchReLU(128, 64, kernel_size=1, stride=1, padding=0, LeakyReLU(negative_slope=0.1))\n",
       "        (7_convbatch): Conv2dBatchReLU(64, 128, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1))\n",
       "        (8_max): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (9_convbatch): Conv2dBatchReLU(128, 256, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1))\n",
       "        (10_convbatch): Conv2dBatchReLU(256, 128, kernel_size=1, stride=1, padding=0, LeakyReLU(negative_slope=0.1))\n",
       "        (11_convbatch): Conv2dBatchReLU(128, 256, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1))\n",
       "        (12_max): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (13_convbatch): Conv2dBatchReLU(256, 512, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1))\n",
       "        (14_convbatch): Conv2dBatchReLU(512, 256, kernel_size=1, stride=1, padding=0, LeakyReLU(negative_slope=0.1))\n",
       "        (15_convbatch): Conv2dBatchReLU(256, 512, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1))\n",
       "        (16_convbatch): Conv2dBatchReLU(512, 256, kernel_size=1, stride=1, padding=0, LeakyReLU(negative_slope=0.1))\n",
       "        (17_convbatch): Conv2dBatchReLU(256, 512, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1))\n",
       "      )\n",
       "    (2): Fusion(\n",
       "      (Combined): Sequential(\n",
       "        (18_max): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (19_convbatch): Conv2dBatchReLU(512, 1024, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1))\n",
       "        (20_convbatch): Conv2dBatchReLU(1024, 512, kernel_size=1, stride=1, padding=0, LeakyReLU(negative_slope=0.1))\n",
       "        (21_convbatch): Conv2dBatchReLU(512, 1024, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1))\n",
       "        (22_convbatch): Conv2dBatchReLU(1024, 512, kernel_size=1, stride=1, padding=0, LeakyReLU(negative_slope=0.1))\n",
       "        (23_convbatch): Conv2dBatchReLU(512, 1024, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1))\n",
       "        (24_convbatch): Conv2dBatchReLU(1024, 1024, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1))\n",
       "        (25_convbatch): Conv2dBatchReLU(1024, 1024, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1))\n",
       "      )\n",
       "    (3): Fusion(\n",
       "      (Combined): Sequential(\n",
       "        (26_convbatch): Conv2dBatchReLU(1280, 1024, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1))\n",
       "        (27_conv): Conv2d(1024, 125, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    (4): Sequential(\n",
       "      (P1_convbatch): Conv2dBatchReLU(512, 64, kernel_size=1, stride=1, padding=0, LeakyReLU(negative_slope=0.1))\n",
       "      (P2_reorg): Reorg(stride=2)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ln.models.YoloFusion(); model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
