{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actity Recognition From RGB-D Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "import lightnet as ln\n",
    "from fastai.vision import *\n",
    "import xml.etree.cElementTree as ET\n",
    "import matplotlib\n",
    "from fastai.metrics import error_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"/home/jupyter/storage/UTKinect_Dataset\"\n",
    "folders = [\"depth\",\"rgb\"]\n",
    "label_fname = \"actionLabel.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_url = \"https://cvrc.ece.utexas.edu/KinectDatasets/depth.zip\"\n",
    "rgb_url = \"https://cvrc.ece.utexas.edu/KinectDatasets/RGB.zip\"\n",
    "label_url = \"https://cvrc.ece.utexas.edu/KinectDatasets/actionLabel.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_url(depth_url,dataset_path+\"/depth.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_url(rgb_url,dataset_path+\"/rgb.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_url(label_url,\"%s/%s\"%(dataset_path,label_fname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_SIZE = 5865\n",
    "data_dict = {\"depth\":[],\"rgb\":[],\"labels\":[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_Arr_to_float(str_arr):\n",
    "    \"\"\"\n",
    "    func: convert all string numbers in list to float\n",
    "    param:  list of string numbers\n",
    "    out:  list of float numbers\n",
    "    \"\"\"\n",
    "    for x in range(len(str_arr)):\n",
    "        str_arr[x] = float(str_arr[x])\n",
    "    return str_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def depth_xml_to_arr(imgFilePath, depthFilePath,beginFrm, endFrm, label):\n",
    "    \"\"\"\n",
    "    func: load depth image data from given range of frames, and append label\n",
    "    param: depthFilePath - path to file where frames are found\n",
    "           beginFrm - first frame of activty \n",
    "           endFrm - last frame of activty\n",
    "           label - label of activity\n",
    "    out: list of touples contatining depth data of each frame between beginFrm and endFrm and label\n",
    "    \"\"\"  \n",
    "    xmlFiles = [f for f in os.listdir(depthFilePath) if f.endswith('.xml')]\n",
    "    xmlFiles.sort(key=lambda item: (len(item), item))\n",
    "    \n",
    "    depthSequence = [[],[]]\n",
    "    \n",
    "    beginFrmFile = \"depthImg%i.xml\" %beginFrm\n",
    "    endFrmFile = \"depthImg%i.xml\" %endFrm\n",
    "    \n",
    "    beginIdx = xmlFiles.index(beginFrmFile)\n",
    "    endIdx = xmlFiles.index(endFrmFile)\n",
    "    useXmlFiles = xmlFiles[beginIdx:endIdx+1]\n",
    "    \n",
    "    for xmlFile in useXmlFiles:\n",
    "        imgFile = xmlFile.replace(\"depthImg\",\"colorImg\").replace(\".xml\",\".jpg\")\n",
    "        img = PIL.Image.open(os.path.join(imgFilePath, imgFile))\n",
    "        \n",
    "        tree = ET.parse(os.path.join(depthFilePath, xmlFile))\n",
    "        filename, _ = os.path.splitext(xmlFile)\n",
    "        elem = tree.find('%s/data' % filename)\n",
    "        strData = elem.text\n",
    "        str_Arr = strData.split()\n",
    "        floatData = string_Arr_to_float(str_Arr)\n",
    "        arr = np.array(floatData)\n",
    "        depthData = np.array(floatData).reshape(240, 320)\n",
    "        \n",
    "        img = img.resize((320,240))\n",
    "        \n",
    "        data_dict[\"rgb\"].append(np.array(img))\n",
    "        data_dict[\"depth\"].append(depthData)\n",
    "        data_dict[\"labels\"].append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should do similar to depth_xml_to_arr, but with rgb images instead of depth\n",
    "def img_to_arr(imgFilePath,beginFrm, endFrm, label):\n",
    "    imgs = []\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_depth_imgs(img_path,depth_path,label_fname):\n",
    "    \"\"\"\n",
    "    func: load depth image data from xml file\n",
    "    param: depth_path - path to folder with depth data\n",
    "           label_fname - name of the label txt file\n",
    "    out: list of touples with depth img and activity label\n",
    "    \"\"\"    \n",
    "    configFile = os.path.join(dataset_path, label_fname)\n",
    "    with open(configFile, \"r\") as f:\n",
    "        lines = f.read().splitlines()\n",
    "\n",
    "    for i in range(0,220,11):\n",
    "        currLines = lines[i:i+11]\n",
    "        depthFileDir = currLines[0]\n",
    "\n",
    "        print(\"loading %s\" %depthFileDir)\n",
    "        for line in currLines[1:]:\n",
    "                splitIdx = line.index(\":\")\n",
    "                label = line[:splitIdx]\n",
    "                nums = line[splitIdx+1:].split()\n",
    "                beginFrm = int(nums[0])\n",
    "                endFrm = int(nums[1])\n",
    "                \n",
    "                depthFilePath = os.path.join(depth_path,depthFileDir)\n",
    "                imgFilePath = os.path.join(img_path,depthFileDir)\n",
    "                \n",
    "                depth_xml_to_arr(imgFilePath, depthFilePath,beginFrm, endFrm, label)\n",
    "    \n",
    "    print(\"loading complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading s01_e01\n",
      "loading s01_e02\n",
      "loading s02_e01\n",
      "loading s02_e02\n",
      "loading s03_e01\n",
      "loading s03_e02\n",
      "loading s04_e01\n",
      "loading s04_e02\n",
      "loading s05_e01\n",
      "loading s05_e02\n",
      "loading s06_e01\n",
      "loading s06_e02\n",
      "loading s07_e01\n",
      "loading s07_e02\n",
      "loading s08_e01\n",
      "loading s08_e02\n",
      "loading s09_e01\n",
      "loading s09_e02\n",
      "loading s10_e01\n",
      "loading s10_e02\n"
     ]
    }
   ],
   "source": [
    "depth_path = dataset_path + \"/depth\"\n",
    "img_path = dataset_path + \"/RGB\"\n",
    "load_depth_imgs(img_path,depth_path,label_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5865"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_dict[\"rgb\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "depthData = torch.from_numpy(np.array(data_dict['depth'])).permute(0,2,1)\n",
    "depthData = depthData[:,None,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5865, 240, 3, 320])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imageData = torch.from_numpy(np.array(data_dict['rgb'])).permute(0,1,3,2)\n",
    "imageData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid shape (3, 320, 240) for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-9c1d0735720d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshow_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimageData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastai/vision/image.py\u001b[0m in \u001b[0;36mshow_image\u001b[0;34m(img, ax, figsize, hide_axis, cmap, alpha, **kwargs)\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0max\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m     \u001b[0mxtr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage2np\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mxtr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mxtr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhide_axis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1563\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1565\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5613\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5615\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5616\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5617\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    697\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[1;32m    698\u001b[0m             raise TypeError(\"Invalid shape {} for image data\"\n\u001b[0;32m--> 699\u001b[0;31m                             .format(self._A.shape))\n\u001b[0m\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid shape (3, 320, 240) for image data"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image(imageData[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YoloFusion(\n",
       "  (layers): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (fuse): Conv2d(4, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1_convbatch): Conv2dBatchReLU(3, 32, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1))\n",
       "    )\n",
       "    (1): Fusion(\n",
       "      (Combined): Sequential(\n",
       "        (2_max): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (3_convbatch): Conv2dBatchReLU(32, 64, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1))\n",
       "        (4_max): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (5_convbatch): Conv2dBatchReLU(64, 128, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1))\n",
       "        (6_convbatch): Conv2dBatchReLU(128, 64, kernel_size=1, stride=1, padding=0, LeakyReLU(negative_slope=0.1))\n",
       "        (7_convbatch): Conv2dBatchReLU(64, 128, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1))\n",
       "        (8_max): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (9_convbatch): Conv2dBatchReLU(128, 256, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1))\n",
       "        (10_convbatch): Conv2dBatchReLU(256, 128, kernel_size=1, stride=1, padding=0, LeakyReLU(negative_slope=0.1))\n",
       "        (11_convbatch): Conv2dBatchReLU(128, 256, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1))\n",
       "        (12_max): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (13_convbatch): Conv2dBatchReLU(256, 512, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1))\n",
       "        (14_convbatch): Conv2dBatchReLU(512, 256, kernel_size=1, stride=1, padding=0, LeakyReLU(negative_slope=0.1))\n",
       "        (15_convbatch): Conv2dBatchReLU(256, 512, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1))\n",
       "        (16_convbatch): Conv2dBatchReLU(512, 256, kernel_size=1, stride=1, padding=0, LeakyReLU(negative_slope=0.1))\n",
       "        (17_convbatch): Conv2dBatchReLU(256, 512, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1))\n",
       "      )\n",
       "    (2): Fusion(\n",
       "      (Combined): Sequential(\n",
       "        (18_max): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (19_convbatch): Conv2dBatchReLU(512, 1024, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1))\n",
       "        (20_convbatch): Conv2dBatchReLU(1024, 512, kernel_size=1, stride=1, padding=0, LeakyReLU(negative_slope=0.1))\n",
       "        (21_convbatch): Conv2dBatchReLU(512, 1024, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1))\n",
       "        (22_convbatch): Conv2dBatchReLU(1024, 512, kernel_size=1, stride=1, padding=0, LeakyReLU(negative_slope=0.1))\n",
       "        (23_convbatch): Conv2dBatchReLU(512, 1024, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1))\n",
       "        (24_convbatch): Conv2dBatchReLU(1024, 1024, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1))\n",
       "        (25_convbatch): Conv2dBatchReLU(1024, 1024, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1))\n",
       "      )\n",
       "    (3): Fusion(\n",
       "      (Combined): Sequential(\n",
       "        (26_convbatch): Conv2dBatchReLU(1280, 1024, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1))\n",
       "        (27_conv): Conv2d(1024, 125, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    (4): Sequential(\n",
       "      (P1_convbatch): Conv2dBatchReLU(512, 64, kernel_size=1, stride=1, padding=0, LeakyReLU(negative_slope=0.1))\n",
       "      (P2_reorg): Reorg(stride=2)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ln.models.YoloFusion(); model"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cu101.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu101:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
