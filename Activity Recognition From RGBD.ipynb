{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actity Recognition From RGB-D Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import lightnet as ln\n",
    "from fastai.vision import *\n",
    "import xml.etree.cElementTree as ET\n",
    "from fastai.metrics import error_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"/home/jupyter/storage/UTKinect_Dataset\"\n",
    "folders = [\"depth\",\"rgb\"]\n",
    "label_fname = \"actionLabel.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_url = \"https://cvrc.ece.utexas.edu/KinectDatasets/depth.zip\"\n",
    "rgb_url = \"https://cvrc.ece.utexas.edu/KinectDatasets/RGB.zip\"\n",
    "label_url = \"https://cvrc.ece.utexas.edu/KinectDatasets/actionLabel.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_url(depth_url,dataset_path+\"/depth.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_url(rgb_url,dataset_path+\"/rgb.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_url(label_url,\"%s/%s\"%(dataset_path,label_fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_Arr_to_float(str_arr):\n",
    "    \"\"\"\n",
    "    func: convert all string numbers in list to float\n",
    "    param:  list of string numbers\n",
    "    out:  list of float numbers\n",
    "    \"\"\"\n",
    "    for x in range(len(str_arr)):\n",
    "        str_arr[x] = float(str_arr[x])\n",
    "    return str_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def depth_xml_to_arr(depthFilePath,beginFrm, endFrm, label):\n",
    "    \"\"\"\n",
    "    func: load depth image data from given range of frames, and append label\n",
    "    param: depthFilePath - path to file where frames are found\n",
    "           beginFrm - first frame of activty \n",
    "           endFrm - last frame of activty\n",
    "           label - label of activity\n",
    "    out: list of touples contatining depth data of each frame between beginFrm and endFrm and label\n",
    "    \"\"\"\n",
    "    xmlFiles = [f for f in os.listdir(depthFilePath) if f.endswith('.xml')]\n",
    "    xmlFiles.sort(key=lambda item: (len(item), item))\n",
    "    \n",
    "    depthSequence = []\n",
    "    \n",
    "    beginFrmFile = \"depthImg%i.xml\" %beginFrm\n",
    "    endFrmFile = \"depthImg%i.xml\" %endFrm\n",
    "    \n",
    "    beginIdx = xmlFiles.index(beginFrmFile)\n",
    "    endIdx = xmlFiles.index(endFrmFile)\n",
    "    useXmlFiles = xmlFiles[beginIdx:endIdx+1]\n",
    "    \n",
    "    for xmlFile in useXmlFiles:\n",
    "        try:\n",
    "            tree = ET.parse(os.path.join(depthFilePath, xmlFile))\n",
    "            filename, _ = os.path.splitext(xmlFile)\n",
    "            elem = tree.find('%s/data' % filename)\n",
    "            strData = elem.text\n",
    "            str_Arr = strData.split()\n",
    "            floatData = string_Arr_to_float(str_Arr)\n",
    "            arr = np.array(floatData)\n",
    "            depthData = np.array(floatData).reshape(240, 320)\n",
    "            depthSequence.append((depthData,label))\n",
    "        except:\n",
    "            print(\"Problem in: %s\" %xmlFile)\n",
    "    return depthSequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should do similar to depth_xml_to_arr, but with rgb images instead of depth\n",
    "def img_to_arr(imgFilePath,beginFrm, endFrm, label):\n",
    "    imgs = []\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_depth_imgs(depth_path,label_fname):\n",
    "    \"\"\"\n",
    "    func: load depth image data from xml file\n",
    "    param: depth_path - path to folder with depth data\n",
    "           label_fname - name of the label txt file\n",
    "    out: list of touples with depth img and activity label\n",
    "    \"\"\"\n",
    "    depth_data = []\n",
    "    \n",
    "    configFile = os.path.join(dataset_path, label_fname)\n",
    "    with open(configFile, \"r\") as f:\n",
    "        lines = f.read().splitlines()\n",
    "\n",
    "    for i in range(0,220,11):\n",
    "        currLines = lines[i:i+11]\n",
    "        depthFileDir = currLines[0]\n",
    "\n",
    "        print(\"loading %s\" %depthFileDir)\n",
    "        for line in currLines[1:]:\n",
    "                splitIdx = line.index(\":\")\n",
    "                label = line[:splitIdx]\n",
    "                nums = line[splitIdx+1:].split()\n",
    "                beginFrm = int(nums[0])\n",
    "                endFrm = int(nums[1])\n",
    "                depthFilePath = os.path.join(depth_path,depthFileDir)\n",
    "                depth_data.extend(depth_xml_to_arr(depthFilePath,beginFrm, endFrm, label))\n",
    "        \n",
    "    return depth_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading s01_e01\n",
      "loading s01_e02\n",
      "loading s02_e01\n",
      "loading s02_e02\n",
      "loading s03_e01\n",
      "loading s03_e02\n",
      "loading s04_e01\n",
      "loading s04_e02\n",
      "loading s05_e01\n",
      "loading s05_e02\n",
      "loading s06_e01\n",
      "loading s06_e02\n",
      "loading s07_e01\n",
      "loading s07_e02\n",
      "loading s08_e01\n",
      "loading s08_e02\n",
      "loading s09_e01\n",
      "loading s09_e02\n",
      "loading s10_e01\n",
      "loading s10_e02\n"
     ]
    }
   ],
   "source": [
    "depth_path = dataset_path + \"/depth\"\n",
    "img_list = load_depth_imgs(depth_path,label_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5866"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(img_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YoloFusion(\n",
       "  (layers): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (fuse): Conv2d(4, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1_convbatch): Conv2dBatchReLU(3, 32, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1))\n",
       "    )\n",
       "    (1): Fusion(\n",
       "      (Combined): Sequential(\n",
       "        (2_max): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (3_convbatch): Conv2dBatchReLU(32, 64, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1))\n",
       "        (4_max): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (5_convbatch): Conv2dBatchReLU(64, 128, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1))\n",
       "        (6_convbatch): Conv2dBatchReLU(128, 64, kernel_size=1, stride=1, padding=0, LeakyReLU(negative_slope=0.1))\n",
       "        (7_convbatch): Conv2dBatchReLU(64, 128, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1))\n",
       "        (8_max): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (9_convbatch): Conv2dBatchReLU(128, 256, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1))\n",
       "        (10_convbatch): Conv2dBatchReLU(256, 128, kernel_size=1, stride=1, padding=0, LeakyReLU(negative_slope=0.1))\n",
       "        (11_convbatch): Conv2dBatchReLU(128, 256, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1))\n",
       "        (12_max): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (13_convbatch): Conv2dBatchReLU(256, 512, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1))\n",
       "        (14_convbatch): Conv2dBatchReLU(512, 256, kernel_size=1, stride=1, padding=0, LeakyReLU(negative_slope=0.1))\n",
       "        (15_convbatch): Conv2dBatchReLU(256, 512, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1))\n",
       "        (16_convbatch): Conv2dBatchReLU(512, 256, kernel_size=1, stride=1, padding=0, LeakyReLU(negative_slope=0.1))\n",
       "        (17_convbatch): Conv2dBatchReLU(256, 512, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1))\n",
       "      )\n",
       "    (2): Fusion(\n",
       "      (Combined): Sequential(\n",
       "        (18_max): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (19_convbatch): Conv2dBatchReLU(512, 1024, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1))\n",
       "        (20_convbatch): Conv2dBatchReLU(1024, 512, kernel_size=1, stride=1, padding=0, LeakyReLU(negative_slope=0.1))\n",
       "        (21_convbatch): Conv2dBatchReLU(512, 1024, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1))\n",
       "        (22_convbatch): Conv2dBatchReLU(1024, 512, kernel_size=1, stride=1, padding=0, LeakyReLU(negative_slope=0.1))\n",
       "        (23_convbatch): Conv2dBatchReLU(512, 1024, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1))\n",
       "        (24_convbatch): Conv2dBatchReLU(1024, 1024, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1))\n",
       "        (25_convbatch): Conv2dBatchReLU(1024, 1024, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1))\n",
       "      )\n",
       "    (3): Fusion(\n",
       "      (Combined): Sequential(\n",
       "        (26_convbatch): Conv2dBatchReLU(1280, 1024, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1))\n",
       "        (27_conv): Conv2d(1024, 125, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    (4): Sequential(\n",
       "      (P1_convbatch): Conv2dBatchReLU(512, 64, kernel_size=1, stride=1, padding=0, LeakyReLU(negative_slope=0.1))\n",
       "      (P2_reorg): Reorg(stride=2)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ln.models.YoloFusion(); model"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cu101.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu101:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
